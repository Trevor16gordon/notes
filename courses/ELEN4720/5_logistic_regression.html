
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Logistic Regression Classifier From Scratch &#8212; Columbia MS EE Notes</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Gaussian Processes ML Model From Scratch" href="6_gaussian_processes.html" />
    <link rel="prev" title="Naive Bayes Classifier From Scratch" href="4_naive_bayes.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Columbia MS EE Notes</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Intro
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Course Notes
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../ELEN4720_overview.html">
   Machine Learning for signals, information, data
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="1_intro.html">
     Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="2_regression.html">
     Ridge / Polynomial Regression From Scratch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="4_naive_bayes.html">
     Naive Bayes Classifier From Scratch
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Logistic Regression Classifier From Scratch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="6_gaussian_processes.html">
     Gaussian Processes ML Model From Scratch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="baysians_classifier.html">
     Baysian Classifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="boosting.html">
     Implementing a boosting algorithm for a classifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="k_means_clustering.html">
     K Mean Clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ECBM4040_overview.html">
   Neural Networks and Deep Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ECBM4040/1_feed_forward_networks.html">
     Feed Forward Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ECBM4040/2_optimizers.html">
     Optimizers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ECBM4040/3_cnn.html">
     Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ECBM4040/3_dropout.html">
     Methods For Improving Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ECBM4040/7_recurren_neural_netowkrs.html">
     Recurrent Neural Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ELEN6885_overview.html">
   Reinforcement Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ELEN6885/1_1_overview.html">
     Overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ELEN6885/1_2_bandit_problems.html">
     Bandit Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ELEN6885/2_mdp.html">
     Markov Decision Processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ELEN6885/3_model_based_rl.html">
     Model Based RL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ELEN6885/4_model_free_rl.html">
     Model Free RL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ELEN6885/6_deep_reinforcement_learning.html">
     Deep Reinforcement Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ELEN6885/99_assignment1.html">
     ELEN 6885 Assignment 1 - Trevor Gordon
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ELEN6885/rl_balancing_exploration_notebook.html">
     Simple Reinforcement Algorithms From Scratch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../EECS4750_overview.html">
   Heterogeneous Computing for Signal and Data Processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../EECS4750/1_intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../EECS4750/2_overview.html">
     Overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../EECS4750/3_block_grid_size.html">
     Block And Grid Size
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Other Notes
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../chapters/Notes/feedforward_neural_network.html">
   Neural Networks
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/courses/ELEN4720/5_logistic_regression.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://trevor16gordon.github.io/notes/"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://trevor16gordon.github.io/notes//issues/new?title=Issue%20on%20page%20%2Fcourses/ELEN4720/5_logistic_regression.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Logistic Regression Classifier From Scratch
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-data">
   Load Data
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-the-logistic-regression-classifier-does">
   What the Logistic Regression Classifier does
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     Training
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#predicting">
     Predicting
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="logistic-regression-classifier-from-scratch">
<h1>Logistic Regression Classifier From Scratch<a class="headerlink" href="#logistic-regression-classifier-from-scratch" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">pdb</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="load-data">
<h1>Load Data<a class="headerlink" href="#load-data" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">base_path</span> <span class="o">=</span> <span class="s2">&quot;/Users/trevorgordon/Library/Mobile Documents/com~apple~CloudDocs/Documents/root/Columbia/Fall2021/ELEN4720/Assignments/assignment2/&quot;</span>

<span class="n">X_all</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">base_path</span> <span class="o">+</span> <span class="s2">&quot;hw2-data/Bayes_classifier/X.csv&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">one_col</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X_all</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">X_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">X_all</span><span class="p">,</span> <span class="n">one_col</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_all</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">base_path</span> <span class="o">+</span> <span class="s2">&quot;hw2-data/Bayes_classifier/y.csv&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">y_all</span> <span class="o">=</span> <span class="n">y_all</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_all</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_all</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="what-the-logistic-regression-classifier-does">
<h1>What the Logistic Regression Classifier does<a class="headerlink" href="#what-the-logistic-regression-classifier-does" title="Permalink to this headline">¶</a></h1>
<div class="section" id="training">
<h2>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li></li>
</ul>
</div>
<div class="section" id="predicting">
<h2>Predicting<a class="headerlink" href="#predicting" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sigmoid function implementation&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">x</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">logistic_regression_loss_vectorized</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">reg</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Logistic regression loss function, vectorized version.</span>
<span class="sd">    Use this linear classification method to find optimal decision boundary.</span>

<span class="sd">    Inputs and outputs are the same as softmax_loss_naive.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># Initialize the gradient to zero</span>
    <span class="n">dW</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">W</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">sig_f</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">loss_a</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sig_f</span><span class="p">))</span><span class="o">/</span><span class="n">n</span>
    <span class="n">loss_b</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">y</span><span class="p">)</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">sig_f</span><span class="p">))</span><span class="o">/</span><span class="n">n</span> 
    <span class="n">loss_c</span> <span class="o">=</span> <span class="n">reg</span><span class="o">*</span><span class="p">(</span><span class="n">W</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_a</span> <span class="o">+</span> <span class="n">loss_b</span> <span class="o">+</span> <span class="n">loss_c</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">dW</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">sig_f</span><span class="p">)</span>
    <span class="n">dW</span> <span class="o">=</span> <span class="n">dW</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">dW</span> <span class="o">-=</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">reg</span><span class="o">*</span><span class="p">(</span><span class="n">W</span><span class="p">))</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">loss</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dW</span>

<span class="k">def</span> <span class="nf">newtons_method_loss</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W_old</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">reg</span><span class="p">):</span>

    <span class="n">dW</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">y_t</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">W</span>
    
    <span class="n">sig_f</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">loss_a</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_t</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sig_f</span><span class="p">))</span><span class="o">/</span><span class="n">n</span>
    <span class="n">loss_b</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">y_t</span><span class="p">)</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">sig_f</span><span class="p">))</span><span class="o">/</span><span class="n">n</span> 
    <span class="n">loss_c</span> <span class="o">=</span> <span class="n">reg</span><span class="o">*</span><span class="p">(</span><span class="n">W</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="p">(</span><span class="n">loss_a</span> <span class="o">+</span> <span class="n">loss_b</span> <span class="o">+</span> <span class="n">loss_c</span><span class="p">)</span>

    <span class="n">dW</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">sig_f</span><span class="p">)</span>
    <span class="n">dW</span> <span class="o">=</span> <span class="n">dW</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">D</span> <span class="o">=</span> <span class="p">(</span><span class="n">sig_f</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sig_f</span><span class="p">))</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">D</span><span class="p">))</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
    <span class="n">H</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">D</span> <span class="o">@</span> <span class="n">X</span>
    <span class="n">weight_change</span> <span class="o">=</span> <span class="p">(</span><span class="n">W</span> <span class="o">-</span> <span class="n">W_old</span><span class="p">)</span>
    <span class="n">grad_term</span> <span class="o">=</span> <span class="n">weight_change</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">dW</span>
    <span class="n">sec_grad_term</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">weight_change</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">H</span> <span class="o">@</span> <span class="n">weight_change</span>
    <span class="n">loss_prime</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">grad_term</span> <span class="o">+</span> <span class="n">sec_grad_term</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">dW_update</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">H</span><span class="p">)</span> <span class="o">@</span> <span class="n">dW</span>
        <span class="k">return</span> <span class="n">loss_prime</span><span class="p">,</span>  <span class="n">dW_update</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;couldn&#39;t calculate hessian&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span>  <span class="n">dW</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BasicClassifier</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Basic classifier </span>
<span class="sd">    </span>
<span class="sd">    - Training is done batched gradient descent</span>
<span class="sd">    - f = X * W</span>
<span class="sd">    - </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">initialize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">old_weights</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.00002</span><span class="p">,</span> <span class="n">training_iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This function will implement batched gradient descent</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">num_train</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
        <span class="n">num_predictors</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span><span class="p">(</span><span class="n">num_predictors</span><span class="p">)</span>
        
        <span class="n">all_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">training_iterations</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">batch_size</span><span class="p">:</span>
                <span class="n">random_iis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_train</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
                <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">random_iis</span><span class="p">]</span>
                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">random_iis</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_train</span>
                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_train</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">dW</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">,</span> <span class="n">regularization</span><span class="o">=</span><span class="n">reg</span><span class="p">)</span>
            <span class="n">all_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">old_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">+=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dW</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;iteration </span><span class="si">%d</span><span class="s1"> / </span><span class="si">%d</span><span class="s1">: loss </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">training_iterations</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">all_loss</span>

    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Inherit this class and overwrite this function.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit the input data</span>

<span class="sd">        After this function the model parameters will be fit. We need to have:</span>
<span class="sd">        -</span>

<span class="sd">        Args:</span>
<span class="sd">            X_train (np.array): Training features</span>
<span class="sd">            y_train (np.array): Single column for the binary predicted class either 0 or 1</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict new data</span>

<span class="sd">        To predict we need to:</span>
<span class="sd">            - Calculate the probability of being either class</span>
<span class="sd">            - Choose the class with the higher probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="k">return</span> <span class="n">probs</span> <span class="o">&gt;</span> <span class="mi">0</span>



<span class="k">class</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">BasicClassifier</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;LogisticRegression</span>

<span class="sd">    This is an implementation from scratch that has the following:</span>
<span class="sd">    - Input data x is assumed to follow a poisson distribution with prior gamma(2,1)</span>
<span class="sd">    - Y follows a bernoulli</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;method&quot;</span><span class="p">,</span> <span class="s2">&quot;grad_desc&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    
    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">regularization</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;grad_desc&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">logistic_regression_loss_vectorized</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">regularization</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;newton&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">newtons_method_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">old_weights</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">regularization</span><span class="p">)</span>

    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_test_1_y_pred_1</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">y_test_0_y_pred_0</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">y_test_1_y_pred_0</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">y_test_0_y_pred_1</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">all_losses</span> <span class="o">=</span> <span class="p">[]</span>


<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_all</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------------------ NEW TEST ------------------------------------&quot;</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_all</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X_all</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_all</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y_all</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>

    <span class="n">cl</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

    <span class="n">loss_data</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="o">/</span><span class="mi">4600</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4600</span><span class="p">,</span> <span class="n">training_iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">all_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_data</span><span class="p">)</span>
    

    <span class="n">joined</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y_pred&quot;</span><span class="p">]),</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y_test&quot;</span><span class="p">])],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">joined</span><span class="p">[</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">joined</span><span class="p">[</span><span class="s2">&quot;y_pred&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">joined</span><span class="p">[</span><span class="s2">&quot;y_test&quot;</span><span class="p">]</span>
    <span class="n">y_test_1_y_pred_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">joined</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">joined</span><span class="p">[</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">True</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">joined</span><span class="p">[</span><span class="s2">&quot;y_test&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">())</span> <span class="c1"># /len(y_test)</span>
    <span class="n">y_test_0_y_pred_0</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">joined</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">joined</span><span class="p">[</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">True</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">joined</span><span class="p">[</span><span class="s2">&quot;y_test&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">())</span> <span class="c1"># /len(y_test)</span>
    <span class="n">y_test_1_y_pred_0</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">joined</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">joined</span><span class="p">[</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">False</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">joined</span><span class="p">[</span><span class="s2">&quot;y_test&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">())</span> <span class="c1"># /len(y_test)</span>
    <span class="n">y_test_0_y_pred_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">joined</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">joined</span><span class="p">[</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">False</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">joined</span><span class="p">[</span><span class="s2">&quot;y_test&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">())</span> <span class="c1"># /len(y_test)</span>
    
<span class="n">y_test_0_y_pred_0_avg</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y_test_0_y_pred_0</span><span class="p">)</span><span class="c1">#/len(y_test_0_y_pred_0)</span>
<span class="n">y_test_0_y_pred_1_avg</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y_test_0_y_pred_1</span><span class="p">)</span><span class="c1">#/len(y_test_0_y_pred_1)</span>
<span class="n">y_test_1_y_pred_0_avg</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y_test_1_y_pred_0</span><span class="p">)</span><span class="c1">#/len(y_test_1_y_pred_0)</span>
<span class="n">y_test_1_y_pred_1_avg</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y_test_1_y_pred_1</span><span class="p">)</span><span class="c1">#/len(y_test_1_y_pred_1)</span>
<span class="p">[[</span><span class="n">y_test_0_y_pred_0_avg</span><span class="p">,</span> <span class="n">y_test_0_y_pred_1_avg</span><span class="p">],</span> <span class="p">[</span><span class="n">y_test_1_y_pred_0_avg</span><span class="p">,</span> <span class="n">y_test_1_y_pred_1_avg</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>------------------------------------ NEW TEST ------------------------------------
iteration 0 / 1000: loss 0.693338
iteration 100 / 1000: loss 0.251873
iteration 200 / 1000: loss 0.252365
iteration 300 / 1000: loss 0.238385
iteration 400 / 1000: loss 0.231796
iteration 500 / 1000: loss 0.229947
iteration 600 / 1000: loss 0.236804
iteration 700 / 1000: loss 0.226493
iteration 800 / 1000: loss 0.218084
iteration 900 / 1000: loss 0.238149
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 1000: loss 0.689797
iteration 100 / 1000: loss 0.268992
iteration 200 / 1000: loss 0.239548
iteration 300 / 1000: loss 0.221198
iteration 400 / 1000: loss 0.234766
iteration 500 / 1000: loss 0.242028
iteration 600 / 1000: loss 0.234222
iteration 700 / 1000: loss 0.211606
iteration 800 / 1000: loss 0.230107
iteration 900 / 1000: loss 0.224818
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 1000: loss 0.694960
iteration 100 / 1000: loss 0.259222
iteration 200 / 1000: loss 0.235367
iteration 300 / 1000: loss 0.242880
iteration 400 / 1000: loss 0.219167
iteration 500 / 1000: loss 0.230105
iteration 600 / 1000: loss 0.207111
iteration 700 / 1000: loss 0.215106
iteration 800 / 1000: loss 0.216111
iteration 900 / 1000: loss 0.212244
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 1000: loss 0.699765
iteration 100 / 1000: loss 0.260444
iteration 200 / 1000: loss 0.234967
iteration 300 / 1000: loss 0.244606
iteration 400 / 1000: loss 0.237865
iteration 500 / 1000: loss 0.231662
iteration 600 / 1000: loss 0.222048
iteration 700 / 1000: loss 0.233446
iteration 800 / 1000: loss 0.229500
iteration 900 / 1000: loss 0.222170
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 1000: loss 0.705172
iteration 100 / 1000: loss 0.275688
iteration 200 / 1000: loss 0.244210
iteration 300 / 1000: loss 0.225495
iteration 400 / 1000: loss 0.235525
iteration 500 / 1000: loss 0.216396
iteration 600 / 1000: loss 0.222978
iteration 700 / 1000: loss 0.220578
iteration 800 / 1000: loss 0.226043
iteration 900 / 1000: loss 0.230722
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 1000: loss 0.683745
iteration 100 / 1000: loss 0.260351
iteration 200 / 1000: loss 0.242471
iteration 300 / 1000: loss 0.229436
iteration 400 / 1000: loss 0.235933
iteration 500 / 1000: loss 0.224015
iteration 600 / 1000: loss 0.231310
iteration 700 / 1000: loss 0.216398
iteration 800 / 1000: loss 0.221467
iteration 900 / 1000: loss 0.231145
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 1000: loss 0.695688
iteration 100 / 1000: loss 0.262743
iteration 200 / 1000: loss 0.249293
iteration 300 / 1000: loss 0.228835
iteration 400 / 1000: loss 0.223385
iteration 500 / 1000: loss 0.233774
iteration 600 / 1000: loss 0.221300
iteration 700 / 1000: loss 0.218937
iteration 800 / 1000: loss 0.228179
iteration 900 / 1000: loss 0.229817
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 1000: loss 0.696781
iteration 100 / 1000: loss 0.244868
iteration 200 / 1000: loss 0.232828
iteration 300 / 1000: loss 0.235825
iteration 400 / 1000: loss 0.234470
iteration 500 / 1000: loss 0.226503
iteration 600 / 1000: loss 0.216168
iteration 700 / 1000: loss 0.224080
iteration 800 / 1000: loss 0.226948
iteration 900 / 1000: loss 0.227838
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 1000: loss 0.695735
iteration 100 / 1000: loss 0.254271
iteration 200 / 1000: loss 0.245869
iteration 300 / 1000: loss 0.241588
iteration 400 / 1000: loss 0.241768
iteration 500 / 1000: loss 0.242216
iteration 600 / 1000: loss 0.220520
iteration 700 / 1000: loss 0.215727
iteration 800 / 1000: loss 0.215945
iteration 900 / 1000: loss 0.202599
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 1000: loss 0.701012
iteration 100 / 1000: loss 0.259311
iteration 200 / 1000: loss 0.257707
iteration 300 / 1000: loss 0.233409
iteration 400 / 1000: loss 0.225577
iteration 500 / 1000: loss 0.222956
iteration 600 / 1000: loss 0.232151
iteration 700 / 1000: loss 0.234612
iteration 800 / 1000: loss 0.225102
iteration 900 / 1000: loss 0.217476
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[2619, 168], [168, 1645]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">all_losses_df</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">all_losses</span><span class="p">)</span>
<span class="n">all_losses_df</span> <span class="o">=</span> <span class="n">all_losses_df</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_losses_df</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_losses_df</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">all_losses_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">all_losses_df</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">all_losses_df</span><span class="p">[</span><span class="s2">&quot;iter&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_losses_df</span><span class="o">.</span><span class="n">index</span>
<span class="n">all_losses_df</span> <span class="o">=</span> <span class="n">all_losses_df</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;iter&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">chartify</span>
<span class="n">ch</span> <span class="o">=</span> <span class="n">chartify</span><span class="o">.</span><span class="n">Chart</span><span class="p">(</span><span class="n">blank_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ch</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Training Error For Logistic Regression Using Gradient Descent&quot;</span><span class="p">)</span>
<span class="n">ch</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">line</span><span class="p">(</span>
    <span class="n">data_frame</span><span class="o">=</span><span class="n">all_losses_df</span><span class="p">,</span>
    <span class="n">color_column</span><span class="o">=</span><span class="s2">&quot;variable&quot;</span><span class="p">,</span>
    <span class="n">x_column</span><span class="o">=</span><span class="s1">&#39;iter&#39;</span><span class="p">,</span>
    <span class="n">y_column</span><span class="o">=</span><span class="s2">&quot;value&quot;</span><span class="p">)</span>
<span class="n">ch</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">set_yaxis_label</span><span class="p">(</span><span class="s2">&quot;Training Loss&quot;</span><span class="p">)</span>
<span class="n">ch</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">set_xaxis_label</span><span class="p">(</span><span class="s2">&quot;Iteration&quot;</span><span class="p">)</span>
<span class="n">ch</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">set_xaxis_tick_orientation</span><span class="p">(</span><span class="s2">&quot;vertical&quot;</span><span class="p">)</span>
<span class="n">ch</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/5_logistic_regression_9_0.png" src="../../_images/5_logistic_regression_9_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_test_1_y_pred_1</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">y_test_0_y_pred_0</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">y_test_1_y_pred_0</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">y_test_0_y_pred_1</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">all_losses</span> <span class="o">=</span> <span class="p">[]</span>


<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_all</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------------------ NEW TEST ------------------------------------&quot;</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_all</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X_all</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_all</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y_all</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>

    <span class="n">cl</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;newton&quot;</span><span class="p">)</span>

    <span class="n">loss_data</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4600</span><span class="p">,</span> <span class="n">training_iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">loss_data</span> <span class="o">=</span> <span class="n">loss_data</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="c1"># First loss point is incorrect as old weights are initialized as random.</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">all_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_data</span><span class="p">)</span>
    

    <span class="n">joined</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y_pred&quot;</span><span class="p">]),</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y_test&quot;</span><span class="p">])],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">joined</span><span class="p">[</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">joined</span><span class="p">[</span><span class="s2">&quot;y_pred&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">joined</span><span class="p">[</span><span class="s2">&quot;y_test&quot;</span><span class="p">]</span>
    <span class="n">y_test_1_y_pred_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">joined</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">joined</span><span class="p">[</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">True</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">joined</span><span class="p">[</span><span class="s2">&quot;y_test&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">())</span> <span class="c1"># /len(y_test)</span>
    <span class="n">y_test_0_y_pred_0</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">joined</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">joined</span><span class="p">[</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">True</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">joined</span><span class="p">[</span><span class="s2">&quot;y_test&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">())</span> <span class="c1"># /len(y_test)</span>
    <span class="n">y_test_1_y_pred_0</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">joined</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">joined</span><span class="p">[</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">False</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">joined</span><span class="p">[</span><span class="s2">&quot;y_test&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">())</span> <span class="c1"># /len(y_test)</span>
    <span class="n">y_test_0_y_pred_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">joined</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">joined</span><span class="p">[</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">False</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">joined</span><span class="p">[</span><span class="s2">&quot;y_test&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">())</span> <span class="c1"># /len(y_test)</span>
    
<span class="n">y_test_0_y_pred_0_avg</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y_test_0_y_pred_0</span><span class="p">)</span><span class="c1">#/len(y_test_0_y_pred_0)</span>
<span class="n">y_test_0_y_pred_1_avg</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y_test_0_y_pred_1</span><span class="p">)</span><span class="c1">#/len(y_test_0_y_pred_1)</span>
<span class="n">y_test_1_y_pred_0_avg</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y_test_1_y_pred_0</span><span class="p">)</span><span class="c1">#/len(y_test_1_y_pred_0)</span>
<span class="n">y_test_1_y_pred_1_avg</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y_test_1_y_pred_1</span><span class="p">)</span><span class="c1">#/len(y_test_1_y_pred_1)</span>
<span class="p">[[</span><span class="n">y_test_0_y_pred_0_avg</span><span class="p">,</span> <span class="n">y_test_0_y_pred_1_avg</span><span class="p">],</span> <span class="p">[</span><span class="n">y_test_1_y_pred_0_avg</span><span class="p">,</span> <span class="n">y_test_1_y_pred_1_avg</span><span class="p">]]</span>

<span class="n">all_losses_df</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">all_losses</span><span class="p">)</span>
<span class="n">all_losses_df</span> <span class="o">=</span> <span class="n">all_losses_df</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_losses_df</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_losses_df</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">all_losses_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">all_losses_df</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">all_losses_df</span><span class="p">[</span><span class="s2">&quot;iter&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_losses_df</span><span class="o">.</span><span class="n">index</span>
<span class="n">all_losses_df</span> <span class="o">=</span> <span class="n">all_losses_df</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;iter&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>------------------------------------ NEW TEST ------------------------------------
iteration 0 / 100: loss 5.386685
iteration 10 / 100: loss 0.551464
iteration 20 / 100: loss 0.469033
iteration 30 / 100: loss 0.404728
iteration 40 / 100: loss 0.360218
iteration 50 / 100: loss 0.325921
iteration 60 / 100: loss 0.304358
iteration 70 / 100: loss 0.275884
iteration 80 / 100: loss 0.264748
iteration 90 / 100: loss 0.255908
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 100: loss 42.310915
iteration 10 / 100: loss 0.555417
iteration 20 / 100: loss 0.467349
iteration 30 / 100: loss 0.408300
iteration 40 / 100: loss 0.353922
iteration 50 / 100: loss 0.321344
iteration 60 / 100: loss 0.305691
iteration 70 / 100: loss 0.288014
iteration 80 / 100: loss 0.267775
iteration 90 / 100: loss 0.248305
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 100: loss -25.031761
iteration 10 / 100: loss 0.557433
iteration 20 / 100: loss 0.477213
iteration 30 / 100: loss 0.416873
iteration 40 / 100: loss 0.361537
iteration 50 / 100: loss 0.321883
iteration 60 / 100: loss 0.304800
iteration 70 / 100: loss 0.287660
iteration 80 / 100: loss 0.269336
iteration 90 / 100: loss 0.248903
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 100: loss 30.528837
iteration 10 / 100: loss 0.551031
iteration 20 / 100: loss 0.463414
iteration 30 / 100: loss 0.401767
iteration 40 / 100: loss 0.359394
iteration 50 / 100: loss 0.319109
iteration 60 / 100: loss 0.286834
iteration 70 / 100: loss 0.278384
iteration 80 / 100: loss 0.261990
iteration 90 / 100: loss 0.236833
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 100: loss 13.445705
iteration 10 / 100: loss 0.556595
iteration 20 / 100: loss 0.473645
iteration 30 / 100: loss 0.415790
iteration 40 / 100: loss 0.370013
iteration 50 / 100: loss 0.329283
iteration 60 / 100: loss 0.298607
iteration 70 / 100: loss 0.282531
iteration 80 / 100: loss 0.267891
iteration 90 / 100: loss 0.248635
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 100: loss 21.726099
iteration 10 / 100: loss 0.552229
iteration 20 / 100: loss 0.463161
iteration 30 / 100: loss 0.401680
iteration 40 / 100: loss 0.359074
iteration 50 / 100: loss 0.331660
iteration 60 / 100: loss 0.297245
iteration 70 / 100: loss 0.276254
iteration 80 / 100: loss 0.282319
iteration 90 / 100: loss 0.251745
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 100: loss -11.426540
iteration 10 / 100: loss 0.560810
iteration 20 / 100: loss 0.466372
iteration 30 / 100: loss 0.409518
iteration 40 / 100: loss 0.362517
iteration 50 / 100: loss 0.321551
iteration 60 / 100: loss 0.314079
iteration 70 / 100: loss 0.297554
iteration 80 / 100: loss 0.275870
iteration 90 / 100: loss 0.250509
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 100: loss -1.034172
iteration 10 / 100: loss 0.557082
iteration 20 / 100: loss 0.471490
iteration 30 / 100: loss 0.401966
iteration 40 / 100: loss 0.354702
iteration 50 / 100: loss 0.320846
iteration 60 / 100: loss 0.294687
iteration 70 / 100: loss 0.275676
iteration 80 / 100: loss 0.261202
iteration 90 / 100: loss 0.255754
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 100: loss 2.408370
iteration 10 / 100: loss 0.553849
iteration 20 / 100: loss 0.467830
iteration 30 / 100: loss 0.400140
iteration 40 / 100: loss 0.347183
iteration 50 / 100: loss 0.328577
iteration 60 / 100: loss 0.308173
iteration 70 / 100: loss 0.278331
iteration 80 / 100: loss 0.265669
iteration 90 / 100: loss 0.247958
------------------------------------ NEW TEST ------------------------------------
iteration 0 / 100: loss -44.702608
iteration 10 / 100: loss 0.560846
iteration 20 / 100: loss 0.471508
iteration 30 / 100: loss 0.411060
iteration 40 / 100: loss 0.369080
iteration 50 / 100: loss 0.325981
iteration 60 / 100: loss 0.302911
iteration 70 / 100: loss 0.281368
iteration 80 / 100: loss 0.265409
iteration 90 / 100: loss 0.251709
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="n">y_test_0_y_pred_0_avg</span><span class="p">,</span> <span class="n">y_test_0_y_pred_1_avg</span><span class="p">],</span> <span class="p">[</span><span class="n">y_test_1_y_pred_0_avg</span><span class="p">,</span> <span class="n">y_test_1_y_pred_1_avg</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[2647, 140], [258, 1555]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">chartify</span>
<span class="n">ch</span> <span class="o">=</span> <span class="n">chartify</span><span class="o">.</span><span class="n">Chart</span><span class="p">(</span><span class="n">blank_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ch</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Training Error Using Newtons&quot;</span><span class="p">)</span>
<span class="n">ch</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">line</span><span class="p">(</span>
    <span class="n">data_frame</span><span class="o">=</span><span class="n">all_losses_df</span><span class="p">,</span>
    <span class="n">color_column</span><span class="o">=</span><span class="s2">&quot;variable&quot;</span><span class="p">,</span>
    <span class="n">x_column</span><span class="o">=</span><span class="s1">&#39;iter&#39;</span><span class="p">,</span>
    <span class="n">y_column</span><span class="o">=</span><span class="s2">&quot;value&quot;</span><span class="p">)</span>
<span class="n">ch</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">set_yaxis_label</span><span class="p">(</span><span class="s2">&quot;Training Loss&quot;</span><span class="p">)</span>
<span class="n">ch</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">set_xaxis_label</span><span class="p">(</span><span class="s2">&quot;Iteration&quot;</span><span class="p">)</span>
<span class="n">ch</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">set_xaxis_tick_orientation</span><span class="p">(</span><span class="s2">&quot;vertical&quot;</span><span class="p">)</span>
<span class="n">ch</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="s1">&#39;png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/5_logistic_regression_12_0.png" src="../../_images/5_logistic_regression_12_0.png" />
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./courses/ELEN4720"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="4_naive_bayes.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Naive Bayes Classifier From Scratch</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="6_gaussian_processes.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Gaussian Processes ML Model From Scratch</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Trevor Gordon<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>