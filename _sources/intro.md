# Intro


Welcome! My name is Trevor Gordon and I have just completed my MS in Electrical Engineering at Columbia University with a focus in machine learning and reinforcement learning (Dec 2022).

Please see my LinkedIn for information on my experience: https://www.linkedin.com/in/tgordon-ubc/

I will be using this jupyter book to keep notes on my courses while at Columbia. This includes theory, formulas, code snippets and links to useful resources. These notes are a work in progress as the semester progresses.



**Projects**
- Neural Networks & Deep Learning: Piano music generation using LSTM neural network and TensorFlow. Checkout an explanation and results [here](https://trevor16gordon.github.io/notes/music_gen_rnn.html)
- An Exploration of Socially Driven Multi-Agent Reinforcement Learning Models: Literature review and study on open source multi agent reinforcement learning research. Checkout the [final report](https://github.com/Trevor16gordon/multi_agent_rl_proj/blob/main/RL_Final_Report.pdf)
- GPU Programming Project: Developed random forests from scratch using CUDA and NVIDIA GPU. Checkout the [final report](https://github.com/Trevor16gordon/random-forests-cuda/blob/main/report.pdf) and [code](https://github.com/Trevor16gordon/random-forests-cuda)


# Courses

**Research**
- Reinforcement Learning for wireless communication systems

**Advanced Deep Learning**
- Object Detection classical approaches
  - Gradient Vector, HOG, and SS
  - CNN, DPM and Overfeat
  - R-CNN Family
  - Fast Detection Models
    - YOLO: You Only Look Once
    - SSD: Single Shot MultiBox Detector
    - YOLOv2 / YOLO9000
    - YOLOv3
- GANs

**Sparse Models For High Dimensional Data**
- Course Introduction, Motivating Examples, Linear Algebra Review
- Sparse Solutions, l0, l0 uniqueness, NP-hardness
- l1 relaxation, l1 recovery under incoherence
- Recovery under RIP, random matrices
- Rank minimization: Motivating examples, Nuclear norm relaxation
- Rank RIP (briefly), Matrix completion
- Robust PCA, General low-complexity models
- Optimization I: Review of first order methods, proximal methods, acceleration
- Optimization II: Constraints, Augmented Lagrangian, ADMM
- Nonconvex Optimization: dictionaries, deconvolution, neural networks
- Nonconvex Optimization: geometric theory and intuitions
- Low-Dimensional Models and Neural Networks I: optimization phenomena
- Low-Dimensional Models and Neural Networks II: dedicated constructions, invariance
- Low-Dimensional Models and Neural Networks III: generative models
- Student course project presentations (final exam slot)

**Robot Learning**
- Unsupervised learning: clustering and dimensionality reduction
- Supervised learning I: linear regression
- Supervised learning II: classification, decision trees
- Guest lecture: supervised learning for a robotic hand orthosis
- Learning for Computer Vision: "traditional" methods
- 3D Computer Vision
- Deep Learning: fundamentals, Part I
- Deep Learning: fundamentals, Part II
- Deep Learning architectures: CNNs
- Deep Learning architectures: AEs, RNNs
- Learning dynamics (forward) models
- Reinforcement Learning I: fundamentals, Q-Learning
- Reinforcement Learning II: non-determinism, policy iteration
- Reinforcement Learning III: Deep Q-Networks
- Reinforcement Learning IV: Policy Gradient and Actor Critic
- Open-source tools and libraries for robot learning
- Domain Randomization and Policies with Memory

**Reinforcement Learning**
- [Introduction](https://trevor16gordon.github.io/notes/courses/ELEN6885/1_overview.html)
- Bandit problems and on-line learning
- Markov decision processes, returns and value functions
- RL solutions: dynamic programming methods
- RL solutions: Monte-Carlo methods
- RL solutions: temporal difference methods
- [RL algorithms from scratch and intro to OpenAI Gym](https://trevor16gordon.github.io/notes/courses/ELEN6885/rl_balancing_exploration_notebook.html)
- Eligibility traces.
- Value function approximation
- Models and planning
- Case studies: applications in artificial intelligence
- Deep reinforcement learning

**Neural Networks and Deep Learning**
- Introduction
- Machine Learning Review
- Deep Forward Networks
  - [Implementing a neural network from scratch](https://trevor16gordon.github.io/notes/chapters/Notes/feedforward_neural_network.html)
- Backpropagation
- Machine Learning
- [Optimization for Deep Learning](https://trevor16gordon.github.io/notes/courses/ECBM4040/3_optimizers.html)
- Convolutional Neural Networks
- Regularization for Deep Learning
- Practical Methodology
- RNNs
- Autoencoders
- GANs, Variational Encoders, DLL trends

**Machine Learning for signals, information, data**
- Introduction, maximum likelihood estimation
- Linear regression, least squares, geometric view
- Ridge regression, probabilistic views of linear regression
  - [Ridge regression and polynomial regression from scratch](https://trevor16gordon.github.io/notes/courses/ELEN4720/2_regression.html)
- Bias-variance, Bayes rule, maximum a posteriori
- Bayesian linear regression
- Sparsity, subset selection for linear regression
- Nearest neighbor classification, Bayes classifiers
- Linear classifiers, perceptron
  - [Naive Bayes from scratch](https://trevor16gordon.github.io/notes/courses/ELEN4720/4_naive_bayes.html)
- Logistic regression, Laplace approximation
  - [Logistic regression from scratch](https://trevor16gordon.github.io/notes/courses/ELEN4720/5_logistic_regression.html)
- Kernel methods, Gaussian processes
  - [Gaussian processes from scratch](https://trevor16gordon.github.io/notes/courses/ELEN4720/6_gaussian_processes.html)
- Maximum margin, support vector machines
- Rrees, random forests
- Boosting
- Clustering, k-means	
- EM algorithm, missing data	
- Mixtures of Gaussians	
- Matrix factorization	
- Non-negative matrix factorization	
- Latent factor models, PCA and variations	
- Markov models	
- Hidden Markov models	
- Continuous state-space models	
- Association analysis

**Heterogeneous Computing for Signal and Data Processing**
- Introduction
- GPUs
- OpenCL
- CUDA
- Portability and Scalability in HPC
- Data Parallelism and Threads
- Memory Hierarchy
- Memory Allocation and Data Movement
- Kernel-Based Parallel Programming
- Memory Bandwidth and Coalescing
- Matrix-Matrix Multiplications
- Thread, Warps and Wavefronts
- Thread Scheduling
- Tiled Processing for 1D, 2D
- Control Divergence
- Convolution and Tiled Convolution
- Reduction Kernels
- Atomic Operations
- Histogram Kernel
- Applications: Deep Learning, Imaging, Video, ...
- Profiling and Debugging

